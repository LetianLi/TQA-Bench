[project]
name = "tqa-bench"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "accelerate>=1.9.0",
    "fastapi>=0.116.1",
    "guidance>=0.2.4",
    "hf-xet>=1.1.5",
    "llama-cpp-python", # Compile with $env:CMAKE_ARGS="-DGGML_CUDA=on" and make sure cuda toolkit is installed with `nvcc --version`
    "lmstudio>=1.3.1",
    "openai>=1.97.1",
    "pandas>=2.3.0",
    "pydantic>=2.11.7",
    "pydantic-settings>=2.10.1",
    "rich>=14.0.0",
    "simplejson>=3.20.1",
    "sse-starlette>=3.0.2",
    "starlette>=0.47.2",
    "starlette-context>=0.4.0",
    "tabulate>=0.9.0",
    "tiktoken>=0.9.0",
    "torch>=2.7.1",
    "torchaudio>=2.7.1",
    "torchvision>=0.22.1",
    "tqdm>=4.67.1",
    "transformers>=4.53.2",
    "uvicorn>=0.35.0",
]

[tool.uv.sources]
torch = [
  { index = "pytorch-cu128", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
  { index = "pytorch-cpu", marker = "sys_platform != 'linux' and sys_platform != 'win32'" },
]
torchvision = [
  { index = "pytorch-cu128", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
  { index = "pytorch-cpu", marker = "sys_platform != 'linux' and sys_platform != 'win32'" },
]

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true
